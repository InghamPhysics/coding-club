{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inner-visibility",
   "metadata": {},
   "source": [
    "## Working with medical images\n",
    "---\n",
    "## Part 2 - registration\n",
    "Registration forms the basic element of image registration.\n",
    "\n",
    "1. Resample the moving image into the target image space\n",
    "2. Calculate a metric describing how similar the images look\n",
    "3. Use an optimiser to update the transformation\n",
    "4. Repeat\n",
    "\n",
    "#### To tell the whole truth...\n",
    "Step 1 is not *quite* what happens.\n",
    "\n",
    "Both images are resampled into a **virtual reference image space**. This allows us to apply a transform to both images simulataneously.\n",
    "\n",
    "Why would we want to do this?\n",
    "\n",
    "It let's us define virtual domains in any way we want - not necessarily a grid of points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if you don't have platipy\n",
    "#!pip install git+https://github.com/pyplati/platipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-surrey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if you haven't already cloned the repo\n",
    "#!git clone https://github.com/InghamPhysics/coding-club\n",
    "#import os\n",
    "#os.chdir('./coding-club/medical-images') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from platipy.imaging.visualisation.tools import ImageVisualiser\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-mortgage",
   "metadata": {},
   "source": [
    "To start with, let's go back to the spheres we generated in the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read original image\n",
    "img_original = sitk.ReadImage(\"./output/spheres_original.nii.gz\", sitk.sitkUInt8)\n",
    "# Read image with modified spacing\n",
    "img_modified = sitk.ReadImage(\"./output/spheres_modified_spacing.nii.gz\", sitk.sitkUInt8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-argument",
   "metadata": {},
   "source": [
    "We know that they aren't really aligned if we just resample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample\n",
    "img_modified_res = sitk.Resample(img_modified, img_original, interpolator=sitk.sitkNearestNeighbor)\n",
    "\n",
    "# Visualise\n",
    "vis = ImageVisualiser(img_original, window=[0,1], figure_size_in=5)\n",
    "vis.add_comparison_overlay(img_modified_res)\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-faculty",
   "metadata": {},
   "source": [
    "So let's make an ITK-style pipeline for registering these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-compiler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "reg_pipe = sitk.ImageRegistrationMethod()\n",
    "\n",
    "# Set the registration\n",
    "reg_pipe.SetInitialTransform(sitk.TranslationTransform(3))\n",
    "\n",
    "# A multi-level scheme\n",
    "reg_pipe.SetShrinkFactorsPerLevel((8,4,2))\n",
    "reg_pipe.SetSmoothingSigmasPerLevel((2,1,0))\n",
    "reg_pipe.SetSmoothingSigmasAreSpecifiedInPhysicalUnits(True)\n",
    "\n",
    "\n",
    "# Compare images using mean squared intensity difference\n",
    "# We calculate this at each point\n",
    "reg_pipe.SetMetricAsMeanSquares()\n",
    "reg_pipe.SetMetricSamplingPercentage(1)\n",
    "reg_pipe.SetMetricSamplingStrategy(sitk.ImageRegistrationMethod.REGULAR)\n",
    "\n",
    "# Use gradient descent\n",
    "reg_pipe.SetOptimizerAsGradientDescentLineSearch(\n",
    "    learningRate=1,\n",
    "    numberOfIterations=25\n",
    ")\n",
    "reg_pipe.SetOptimizerScalesFromPhysicalShift(True)\n",
    "\n",
    "# Interpolate using nearest neighbour\n",
    "reg_pipe.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    \n",
    "# Voxel values must be of type double (float64)\n",
    "transform_translation = reg_pipe.Execute(\n",
    "    fixed=sitk.Cast(img_original, sitk.sitkFloat64),\n",
    "    moving=sitk.Cast(img_modified, sitk.sitkFloat64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transform_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-scientist",
   "metadata": {},
   "source": [
    "Now we have to resample, and use the transform we just optimised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_modified_translated = sitk.Resample(\n",
    "    img_modified,\n",
    "    img_original,\n",
    "    transform = transform_translation,\n",
    "    interpolator = sitk.sitkNearestNeighbor,\n",
    "    defaultPixelValue = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise\n",
    "vis = ImageVisualiser(img_original, window=[0,1], figure_size_in=5)\n",
    "vis.add_comparison_overlay(img_modified_translated)\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-causing",
   "metadata": {},
   "source": [
    "Clearly, this isn't a great registration. A major problem is that we aren't accounting for the spatial \"stretching\" caused by changing the image spacing earlier.\n",
    "\n",
    "Fortunately, there are transformation that include this kind of scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "reg_pipe = sitk.ImageRegistrationMethod()\n",
    "\n",
    "# Set the registration\n",
    "reg_pipe.SetInitialTransform(sitk.ScaleVersor3DTransform())\n",
    "\n",
    "# A multi-level scheme\n",
    "reg_pipe.SetShrinkFactorsPerLevel((8,4,2))\n",
    "reg_pipe.SetSmoothingSigmasPerLevel((2,1,0))\n",
    "reg_pipe.SetSmoothingSigmasAreSpecifiedInPhysicalUnits(True)\n",
    "\n",
    "\n",
    "# Compare images using mean squared intensity difference\n",
    "# We calculate this at each point\n",
    "reg_pipe.SetMetricAsMeanSquares()\n",
    "reg_pipe.SetMetricSamplingPercentage(1)\n",
    "reg_pipe.SetMetricSamplingStrategy(sitk.ImageRegistrationMethod.REGULAR)\n",
    "\n",
    "# Use gradient descent\n",
    "reg_pipe.SetOptimizerAsGradientDescentLineSearch(\n",
    "    learningRate=1,\n",
    "    numberOfIterations=25\n",
    ")\n",
    "reg_pipe.SetOptimizerScalesFromPhysicalShift(True)\n",
    "\n",
    "# Interpolate using nearest neighbour\n",
    "reg_pipe.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "                           \n",
    "transform_scaleversor = reg_pipe.Execute(\n",
    "    fixed=sitk.Cast(img_original, sitk.sitkFloat64),\n",
    "    moving=sitk.Cast(img_modified, sitk.sitkFloat64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transform_scaleversor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_modified_scaleversor = sitk.Resample(\n",
    "    img_modified,\n",
    "    img_original,\n",
    "    transform = transform_scaleversor,\n",
    "    interpolator = sitk.sitkNearestNeighbor,\n",
    "    defaultPixelValue = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise\n",
    "vis = ImageVisualiser(img_original, window=[0,1], figure_size_in=5)\n",
    "vis.add_comparison_overlay(img_modified_scaleversor)\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-maria",
   "metadata": {},
   "source": [
    "A little bit better, but because the initial parameters are so far from the ideal it is hard for the optimiser to get to the global minimum.\n",
    "\n",
    "Another issue is that with binary images like ours, there are only two possible values for the mean squared difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platipy.imaging.registration.registration import convert_mask_to_reg_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_struct_original = convert_mask_to_reg_structure(img_original)\n",
    "\n",
    "vis = ImageVisualiser(reg_struct_original, window=(0,1), figure_size_in=5)\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_struct_modified = convert_mask_to_reg_structure(img_modified)\n",
    "\n",
    "vis = ImageVisualiser(reg_struct_modified , window=(0,1), figure_size_in=5)\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial registration\n",
    "alignment_tfm = sitk.CenteredTransformInitializer(\n",
    "    reg_struct_original, reg_struct_modified, sitk.Euler3DTransform(), True\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "reg_pipe = sitk.ImageRegistrationMethod()\n",
    "\n",
    "# Set the registration\n",
    "reg_pipe.SetInitialTransform(sitk.ScaleVersor3DTransform())\n",
    "\n",
    "# Set transform to moving image\n",
    "reg_pipe.SetMovingInitialTransform(alignment_tfm)\n",
    "\n",
    "# Only sample in the \"spheres\"\n",
    "# reg_pipe.SetMetricFixedMask( img_original )\n",
    "# reg_pipe.SetMetricMovingMask( img_modified )\n",
    "\n",
    "# A multi-level scheme\n",
    "reg_pipe.SetShrinkFactorsPerLevel((8,4,2))\n",
    "reg_pipe.SetSmoothingSigmasPerLevel((2,1,0))\n",
    "reg_pipe.SetSmoothingSigmasAreSpecifiedInPhysicalUnits(True)\n",
    "\n",
    "\n",
    "# Compare images using mean squared intensity difference\n",
    "# We calculate this at each point\n",
    "reg_pipe.SetMetricAsMeanSquares()\n",
    "reg_pipe.SetMetricSamplingPercentage(1)\n",
    "reg_pipe.SetMetricSamplingStrategy(sitk.ImageRegistrationMethod.REGULAR)\n",
    "\n",
    "# Use gradient descent\n",
    "reg_pipe.SetOptimizerAsGradientDescentLineSearch(\n",
    "    learningRate=1,\n",
    "    numberOfIterations=25\n",
    ")\n",
    "reg_pipe.SetOptimizerScalesFromPhysicalShift(True)\n",
    "\n",
    "# Interpolate using nearest neighbour\n",
    "reg_pipe.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "                           \n",
    "transform_scaleversor_2 = reg_pipe.Execute(\n",
    "    fixed=reg_struct_original,\n",
    "    moving=reg_struct_modified \n",
    ")\n",
    "\n",
    "# We must combine the transforms\n",
    "combined_transform = sitk.CompositeTransform([alignment_tfm, transform_scaleversor_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_modified_scaleversor_2 = sitk.Resample(\n",
    "    img_modified,\n",
    "    img_original,\n",
    "    transform = combined_transform,\n",
    "    interpolator = sitk.sitkNearestNeighbor,\n",
    "    defaultPixelValue = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise\n",
    "vis = ImageVisualiser(img_original, window=[0,1], figure_size_in=5)\n",
    "vis.add_comparison_overlay(img_modified_scaleversor_2)\n",
    "\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-warner",
   "metadata": {},
   "source": [
    "## Platipy - another abstraction layer\n",
    "\n",
    "It can be a bit of a hassle doing image registration like this.\n",
    "\n",
    "Platipy has some useful tools to make this process a lot easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platipy.imaging.registration.registration import initial_registration, transform_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, transform_platipy = initial_registration(\n",
    "    fixed_image = reg_struct_original,\n",
    "    moving_image = reg_struct_modified,\n",
    "    reg_method = \"ScaleVersor\",\n",
    "    default_value = 0,\n",
    "    shrink_factors = [8,4,2],\n",
    "    optimiser = 'gradient_descent_line_search',\n",
    "    final_interp = sitk.sitkNearestNeighbor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagate transform to the modified spheres image\n",
    "\n",
    "img_modified_scaleversor_3 = transform_propagation(\n",
    "    fixed_image = img_original,\n",
    "    moving_image = img_modified,\n",
    "    transform = transform_platipy,\n",
    "    structure = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-semiconductor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualise\n",
    "vis = ImageVisualiser(img_original, window=[0,1], figure_size_in=5)\n",
    "vis.add_comparison_overlay(img_modified_scaleversor_3)\n",
    "\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-houston",
   "metadata": {},
   "source": [
    "## \"Real\" images\n",
    "\n",
    "Finally, let's check out how we can perform registration on real patient imaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small utility function\n",
    "from platipy.imaging.utils.tools import get_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have some contoured RT imaging\n",
    "\n",
    "img_ct_atlas = sitk.ReadImage(\"./input/HN_CT_ATLAS.nii.gz\")\n",
    "struct_ctv_atlas = sitk.ReadImage(\"./input/HN_CTV_ATLAS.nii.gz\")\n",
    "\n",
    "vis = ImageVisualiser(img_ct_atlas, cut=get_com(struct_ctv_atlas), figure_size_in=5)\n",
    "vis.add_contour({\"CTV\":struct_ctv_atlas})\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also have a PET-CT scan, without any contours\n",
    "\n",
    "img_ct = sitk.ReadImage(\"./input/HN_CT.nii.gz\")\n",
    "img_pt = sitk.ReadImage(\"./input/HN_PT.nii.gz\")\n",
    "\n",
    "img_pt_res = sitk.Resample(img_pt, img_ct)\n",
    "\n",
    "vis = ImageVisualiser(img_ct, figure_size_in=5)\n",
    "vis.add_scalar_overlay(img_pt_res, name=\"PET value\", colormap=plt.cm.magma, max_value=50000)\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the planning CT to the PET-CT\n",
    "\n",
    "img_ct_atlas_rigid, tfm_rigid = initial_registration(\n",
    "    fixed_image = img_ct,\n",
    "    moving_image = img_ct_atlas,\n",
    "    reg_method = \"Similarity\",\n",
    "    default_value = -1000,\n",
    "    final_interp = sitk.sitkLinear\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise\n",
    "\n",
    "vis = ImageVisualiser(img_ct, figure_size_in=5)\n",
    "vis.add_comparison_overlay(img_ct_atlas_rigid)\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-broadway",
   "metadata": {},
   "source": [
    "### Deformable registration\n",
    "\n",
    "To account for non-linear deformations we can use a DIR algorithm.\n",
    "\n",
    "One great option is the fast, symmetric, log-domain differomorphic demons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platipy.imaging.registration.registration import fast_symmetric_forces_demons_registration, apply_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ct_atlas_dir, tfm_dir = fast_symmetric_forces_demons_registration(\n",
    "    fixed_image = img_ct,\n",
    "    moving_image = img_ct_atlas_rigid,\n",
    "    ncores = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise\n",
    "\n",
    "vis = ImageVisualiser(img_ct, figure_size_in=5)\n",
    "vis.add_comparison_overlay(img_ct_atlas_dir)\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-distance",
   "metadata": {},
   "source": [
    "### Propagating transformations\n",
    "\n",
    "Finally, we can apply these transformations to the contours we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_ctv_atlas_rigid = transform_propagation(img_ct, struct_ctv_atlas, tfm_rigid, structure=True)\n",
    "struct_ctv_atlas_dir = apply_field(struct_ctv_atlas_rigid, tfm_dir, structure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay on PET-CT\n",
    "\n",
    "vis = ImageVisualiser(img_ct, cut=get_com(struct_ct_atlas_dir), figure_size_in=5)\n",
    "vis.add_scalar_overlay(img_pt_res, name=\"PET value\", colormap=plt.cm.magma, max_value=50000)\n",
    "vis.add_contour({\"CTV\":struct_ctv_atlas_dir}, color='blue')\n",
    "fig = vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, we could use this contour to extract information from the PET\n",
    "\n",
    "img_pt_masked = sitk.Mask(img_pt_res, struct_ctv_atlas_dir)\n",
    "\n",
    "f = sitk.LabelIntensityStatisticsImageFilter()\n",
    "f.Execute(struct_ctv_atlas_dir, img_pt_res)\n",
    "\n",
    "vol = f.GetNumberOfPixels(1) * np.product(img_pt_res.GetSpacing())/1000\n",
    "max_act = f.GetMaximum(1)\n",
    "mean_act = f.GetMean(1)\n",
    "tot_act = f.GetSum(1) * np.product(img_pt_res.GetSpacing())/1000\n",
    "\n",
    "print(\"CTV information:\")\n",
    "print(f\"Volume:        {vol:.2f} mL\")\n",
    "print(f\"Max. activity: {max_act:.2f} Bq/mL\")\n",
    "print(f\"Mean activity: {mean_act:.2f} Bq/mL\")\n",
    "print(f\"Tot. activity: {tot_act/1e6:.2f} MBq\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
